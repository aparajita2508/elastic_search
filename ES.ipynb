{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch.connection import RequestsHttpConnection\n",
    "\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "\n",
    "from elasticsearch_dsl import Search\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping elasticsearch: True\n"
     ]
    }
   ],
   "source": [
    "# Establishing connection\n",
    "server=\"localhost:9200\"\n",
    "\n",
    "es_server= Elasticsearch(server, connection_class=RequestsHttpConnection)\n",
    "\n",
    "print \"Ping elasticsearch:\",es_server.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_type': u'tweet', u'_seq_no': 5, u'_shards': {u'successful': 1, u'failed': 0, u'total': 2}, u'_index': u'test-index', u'_version': 6, u'_primary_term': 2, u'result': u'updated', u'_id': u'1'}\n",
      "updated\n",
      "{u'_type': u'tweet', u'_seq_no': 2, u'_shards': {u'successful': 1, u'failed': 0, u'total': 2}, u'_index': u'test-index', u'_version': 3, u'_primary_term': 2, u'result': u'updated', u'_id': u'2'}\n",
      "updated\n",
      "{u'_type': u'tweet', u'_seq_no': 1, u'_shards': {u'successful': 1, u'failed': 0, u'total': 2}, u'_index': u'test-index', u'_version': 2, u'_primary_term': 2, u'result': u'updated', u'_id': u'3'}\n",
      "updated\n"
     ]
    }
   ],
   "source": [
    "# Creating small indexes\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(\"localhost:9200\")\n",
    "# 127.0.0.1:9200, 0.0.0.0:9200\n",
    "\n",
    "list_of_doc = [{\n",
    "    'author': 'kimchy',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool.',\n",
    "    'timestamp': datetime.now(),\n",
    "},{\n",
    "    'author': 'kimchy1',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool1.',\n",
    "    'timestamp': datetime.now(),\n",
    "},\n",
    "{\n",
    "    'author': 'kimchy2',\n",
    "    'text': 'Elasticsearch: cool. bonsai cool2.',\n",
    "    'timestamp': datetime.now(),\n",
    "}\n",
    "]\n",
    "idx = 0\n",
    "for doc in list_of_doc:\n",
    "    idx = idx +1\n",
    "    res = es.index(index=\"test-index\", doc_type='tweet', id=idx, body=doc)\n",
    "    print res\n",
    "    print(res['result'])\n",
    "\n",
    "# res = es.get(index=\"test-index\", doc_type='tweet', id=1)\n",
    "# # print res\n",
    "# print(res['_source'])\n",
    "\n",
    "# es.indices.refresh(index=\"test-index\")\n",
    "\n",
    "# res = es.search(index=\"test-index\", body={\"query\": {\"match_all\": {}}})\n",
    "# print res\n",
    "# print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "# for hit in res['hits']['hits']:\n",
    "#     print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indexing cvs files into elastic search\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "with open('/Users/aparajita/Desktop/77_cancer_proteomes_CPTAC_itraq.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    helpers.bulk(es, reader, index='my-index', doc_type='my-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host for Elastic Search: http://127.0.0.1:9200/\n",
      "Port no for Elastic Search: 1\n",
      "Connected: False\n",
      "1. Create index\n",
      "2. Upsert data\n",
      "3. Query\n",
      "4. Exit\n",
      "Enter your option: 1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "def upsert_doc_es(es, index_name, doc_type_name, file_path, identifier_col):\n",
    "    with open(file_path) as f:\n",
    "        csv_file_object = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        # reading the data from the file and capturing the information in the header to use when building our index\n",
    "        header = csv_file_object.next()\n",
    "        header = [item.lower() for item in header]\n",
    "        bulk_data = []  # building up a Python dictionary of data set in a format that the Python ES client can use.\n",
    "        # here we are loading data by means of bulk indexing\n",
    "        for row in csv_file_object:\n",
    "            data_dict = {}\n",
    "            for i in range(len(row)):\n",
    "                data_dict[header[i]] = row[i]\n",
    "            op_dict = {\n",
    "                \"index\": {\n",
    "                    \"_index\": index_name,\n",
    "                    \"_type\": doc_type_name,\n",
    "                    \"_id\": data_dict[identifier_col]\n",
    "                }\n",
    "            }\n",
    "            # bulk index request takes 2 lines for each operation, one is metadata and other is actual data.\n",
    "            # op_dict is metadata\n",
    "            bulk_data.append(op_dict)\n",
    "            # data_dict is actual data\n",
    "            bulk_data.append(data_dict)\n",
    "    res = es.bulk(index=INDEX_NAME, body=bulk_data, refresh=True)\n",
    "\n",
    "\n",
    "# create ES client, create index\n",
    "def create_index(es, INDEX_NAME):\n",
    "    if es.indices.exists(INDEX_NAME):\n",
    "        print \"Index already exists\"\n",
    "        print(\"deleting '%s' index...\" % (INDEX_NAME))\n",
    "        res = es.indices.delete(index=INDEX_NAME)\n",
    "        print(\" response: '%s'\" % (res))\n",
    "    # since we are running locally, use one shard and no replicas\n",
    "    request_body = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    }\n",
    "    print(\"creating '%s' index...\" % (INDEX_NAME))\n",
    "    res = es.indices.create(index=INDEX_NAME, body=request_body)\n",
    "    print(\" response: '%s'\" % (res))\n",
    "\n",
    "    print \"searching response\"\n",
    "    res = es.search(index=INDEX_NAME, size=10, body={\"query\": {\"match_all\": {}}})\n",
    "    print(\" response: '%s'\" % (res))\n",
    "\n",
    "\n",
    "def check_if_indices_exists(es, index_name):\n",
    "    if es.indices.exists(index_name):\n",
    "        print \"Index exists\"\n",
    "        return True\n",
    "    else:\n",
    "        print \"Index doesnt exists\"\n",
    "        return False\n",
    "\n",
    "\n",
    "def search_from(es, index_name, searchFor, searchKey, size):\n",
    "    return es.search(index=index_name, body={\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"name\", \"age\"],\n",
    "        'query': {\n",
    "            'match': {\n",
    "                searchFor: searchKey,\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "\n",
    "def create_index_alias(es, index_name, alias_name):\n",
    "    if check_if_indices_exists(es, index_name):\n",
    "        alias_status = es.indices.put_alias(index=index_name, name=alias_name, body={\n",
    "            \"filter\": {\n",
    "                \"match\": {\n",
    "                    \"TId\": alias_name\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        print \"alias created\", alias_status\n",
    "    else:\n",
    "        print \"index doesn't exist, not creating alias\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    host = raw_input(\"Host for Elastic Search: \")\n",
    "    port = raw_input(\"Port no for Elastic Search: \")\n",
    "    ES_HOST = {\"host\": host, \"port\": port}\n",
    "    # creating ES client\n",
    "    es = Elasticsearch(hosts=[ES_HOST])\n",
    "    print \"Connected: \" + str(es.ping())\n",
    "    while True:\n",
    "        print \"1. Create index\"\n",
    "        print \"2. Upsert data\"\n",
    "        print \"3. Query\"\n",
    "        print \"4. Exit\"\n",
    "        option = int(raw_input(\"Enter your option: \"))\n",
    "        if option == 1:\n",
    "            INDEX_NAME = raw_input(\"Give index name: \")\n",
    "            alias = raw_input(\"Give alias name: \")\n",
    "            # create an index\n",
    "            create_index(es, INDEX_NAME)\n",
    "            create_index_alias(es, INDEX_NAME, alias)\n",
    "\n",
    "        elif option == 2:\n",
    "            INDEX_NAME = raw_input(\"Give index name: \")\n",
    "            doc_type = raw_input(\"Give the document type name\")\n",
    "            file_path = raw_input(\"Give the filepath of the dataset\")\n",
    "            id = raw_input(\"Give the unique id of the dataset\")\n",
    "            upsert_doc_es(es, INDEX_NAME, doc_type, file_path, id)\n",
    "            print(\"Successfully upserted your data...\")\n",
    "        elif option == 3:\n",
    "            INDEX_NAME = raw_input(\"Give index name: \")\n",
    "            field = raw_input(\"Give search field name to search:\")\n",
    "            search_key = raw_input(\"Give search key :\")\n",
    "            size = int(raw_input(\"Give result size:\"))\n",
    "            search_val = search_from(es, INDEX_NAME, field, search_key, size)\n",
    "            for hit in search_val['hits']['hits']:\n",
    "                print(hit['_source']['name'])\n",
    "        elif option == 4:\n",
    "            print(\"Bye! Bye! Exiting.......\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"Invalid option, please select correct option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
